{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of From Excel to Pandas Guide.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f7BH8gRpy_2F",
        "eQFuKbNzy_2b",
        "3HLjj9AJy_2g",
        "dQimVyrVy_2k",
        "RdXHEGQly_2p",
        "tYq8fcEKy_2t",
        "phoohNEEy_2y",
        "6yPr-y69y_23",
        "AlWq6ALay_27",
        "5nPujp5Iy_3B",
        "DPWsToNHy_3K",
        "62yHv5pPy_3T",
        "F7lAy7N8y_3g",
        "FMsuY5Vay_3l",
        "zk4gjZIgy_3n",
        "TufIxfS5y_3q",
        "YYMCr5RFy_3u",
        "0r1jj07jy_30",
        "VaU_5zRcy_34",
        "PHHhLVkiy_4D",
        "p5R2NgN0y_4K",
        "Ld59hD5Cy_4N",
        "fnNt1DCxy_4b",
        "Db3T7jDHy_4g",
        "Z5Fr1FbEy_4j",
        "UwzhFV02y_4k",
        "zcQV6Blhy_48",
        "SKhiS_0Sy_5M",
        "onRIydxny_5Y",
        "6AhBml1jy_5a",
        "NYPBxGuuy_5k",
        "zDw7pEdCy_5s",
        "S3oucpVPy_5t",
        "Bq0emBBey_5w",
        "qicNvDgsy_50",
        "vPXZQRisy_50",
        "gqnJDoW_y_54",
        "dPISXziFy_59",
        "uIOFaq7Ly_59",
        "xzJNeiDby_6C",
        "Cd6fHnPFy_6D"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbtrsv/finapy_project/blob/master/Copy_of_From_Excel_to_Pandas_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m53rebcBy_1H"
      },
      "source": [
        "![sslogo](https://github.com/stratascratch/stratascratch.github.io/raw/master/assets/sslogo.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t_lIvdzy_1J"
      },
      "source": [
        "# From Excel to Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qORXCRDiy_1M"
      },
      "source": [
        "# xlrd is needed to load excel files\n",
        "!pip install xlrd\n",
        "!pip install psycopg2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvS7gahzy_1S"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy  as np\n",
        "import matplotlib.pyplot as plt\n",
        "import psycopg2 as ps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhw3SyP2y_1V"
      },
      "source": [
        "## Loading data from files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqODQrRAy_1X"
      },
      "source": [
        "### Loading from XLSX (Excel format)\n",
        "\n",
        "We will now load a file stored in excel format with 3 sheets called [iris.xlsx](https://github.com/stratascratch/stratascratch.github.io/raw/master/assets/iris.xlsx).\n",
        "\n",
        "These 3 sheets represent the 3 varities of iris flowers as studied by [Fisher](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
        "\n",
        "To load from excel we need to use `pd.read_excel`\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html\n",
        "\n",
        "The main parameters are:\n",
        "- Filepath which tells it where to find the excel file\n",
        "- Sheet name which is very versatile and can be a string, integer or a list of strings and integers. If it is a string it means take a single sheet named with that string. If it is a number it means take a sheet by that number.\n",
        "\n",
        "The dataset intentionally misses headers because we will add them manually and this entails two more parameters which you might need to use often (which are b.t.w. also aplicable to `pd.read_csv`):\n",
        "- header which can be None or a number. If it is a number it means that the row at that number is the header and everything before that number is skiped.\n",
        "- names is a list of strings which are column names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yOhkUF0y_1Y"
      },
      "source": [
        "# One way to load the data\n",
        "column_names = [\"sepal_length\", \"sepal_width\" , \"petal_length\", \"petal_width\", \"variety\"]\n",
        "\n",
        "iris_excel_path = \"https://github.com/stratascratch/stratascratch.github.io/raw/master/assets/iris.xlsx\"\n",
        "\n",
        "setosa_data = pd.read_excel(iris_excel_path, \"Setosa\", header=None, names=column_names) # Setosa is the sheet name\n",
        "versi_data  = pd.read_excel(iris_excel_path, 1, header=None, names=column_names) # 1 is the index of the second sheet\n",
        "virgi_data  = pd.read_excel(iris_excel_path, 2, header=None, names=column_names)\n",
        "\n",
        "# we need to reset the index to have nice linear indices from 0, 1 to 150\n",
        "# reset_index() adds a new column called \"index\" which we drop (explained later)\n",
        "iris = pd.concat([setosa_data, versi_data, virgi_data]).reset_index().drop(\"index\", axis=1)\n",
        "\n",
        "iris.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deP_7BZEy_1c"
      },
      "source": [
        "# Another way to load the data using one call to pd.read_excel\n",
        "# We get a dictionary which we can convert to one data frame using pd.concat again\n",
        "sheets = [\"Setosa\", \"Versicolor\", \"Virginica\"]\n",
        "\n",
        "column_names = [\"sepal_length\", \"sepal_width\" , \"petal_length\", \"petal_width\", \"variety\"]\n",
        "\n",
        "data_frames_dictionary = pd.read_excel(iris_excel_path, sheets, header=None, names=column_names)\n",
        "\n",
        "# values() gives us a list of dataframes\n",
        "data_frames = data_frames_dictionary.values()\n",
        "\n",
        "# we need to reset the index to have nice linear indices from 0, 1 to 150\n",
        "iris = pd.concat(data_frames).reset_index().drop(\"index\", axis=1)\n",
        "\n",
        "print(data_frames_dictionary.keys())\n",
        "\n",
        "iris.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTTVcb7uy_1f"
      },
      "source": [
        "## The iris dataset from database\n",
        "\n",
        "This dataset is also present in the database under `datasets.iris`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAI25jeRy_1h"
      },
      "source": [
        "# Connect to database\n",
        "host_name = 'db-strata.stratascratch.com'\n",
        "dbname = 'db_strata'\n",
        "port = '5432'\n",
        "user_name = '' #enter username\n",
        "pwd = '' #enter your database password found in the profile tab in Strata Scratch\n",
        "\n",
        "try:\n",
        "    conn = ps.connect(host=host_name,database=dbname,user=user_name,password=pwd,port=port)\n",
        "except ps.OperationalError as e:\n",
        "    raise e\n",
        "else:\n",
        "    print('Connected!')\n",
        "\n",
        "def get_dataset(dataset_name):\n",
        "    #Write SQL below to pull datasets \n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"\"\" \n",
        "                SELECT *  FROM {0}; \n",
        "                \"\"\".format(dataset_name))\n",
        "    data = cur.fetchall()\n",
        "    colnames = [desc[0] for desc in cur.description] \n",
        "    conn.commit()\n",
        "\n",
        "    #create the pandas dataframe\n",
        "    dataframe = pd.DataFrame(data, columns=colnames)\n",
        "\n",
        "    #close the connection\n",
        "    cur.close()\n",
        "    \n",
        "    return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IhPk69vy_1l"
      },
      "source": [
        "# We load iris and by the way we also load four more datasets that we'll use later\n",
        "iris = get_dataset(\"iris\")\n",
        "\n",
        "nominee_filmography = get_dataset(\"nominee_filmography\")\n",
        "nominee_information = get_dataset(\"nominee_information\")\n",
        "billboard_top_100 = get_dataset(\"billboard_top_100_year_end\")\n",
        "\n",
        "sat_scores = get_dataset(\"sat_scores\")\n",
        "\n",
        "iris.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSLF_ztby_1p"
      },
      "source": [
        "## Saving data to files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "910YT9yNy_1q"
      },
      "source": [
        "Each dataframe has two methods called `to_csv` and `to_excel` whose documentation can be found at:\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3yBzkUCy_1r"
      },
      "source": [
        "## Simple math in pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbGyW2jwy_1s"
      },
      "source": [
        "You can add together two columns to get an elementwise addition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8vEpmVyy_1u"
      },
      "source": [
        "(iris[\"petal_width\"] + iris[\"sepal_width\"]).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp4sZ34Qy_14"
      },
      "source": [
        "Other operations are also supported (multiplication (`*`), substraction(`-`) and division(`/`)) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdjLA-nky_16"
      },
      "source": [
        "# Get rectangular approximation of petal area using elementwise multiplication\n",
        "(iris[\"petal_length\"] * iris[\"petal_width\"]).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4nRdwH7y_2A"
      },
      "source": [
        "You can also apply operations and scalars.\n",
        "\n",
        "For example you can add a scalar to a column and you can multiply by a scalar.\n",
        "\n",
        "What happens in the background is that the scalar gets replicated into an ndarray which is then processed as described above depending on the operator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm8jpgzSy_2A"
      },
      "source": [
        "(5 * iris[\"sepal_length\"] + 10).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7BH8gRpy_2F"
      },
      "source": [
        "#### Replicating scalars to array in python.\n",
        "\n",
        "In excel you can write a value in cell and then you drag down with your mouse and the value replicates itself to cells below.\n",
        "\n",
        "In python we have a special syntax for this.\n",
        "- `items * amount` where items is a python list (not ndarray) and amount is an integer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2QyhDNZy_2G",
        "collapsed": true
      },
      "source": [
        "[\"plenty\"] * 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSVegm2ly_2L",
        "collapsed": true
      },
      "source": [
        "[5] * 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4VipzbYy_2R",
        "collapsed": true
      },
      "source": [
        "5 * 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM0WE6bzy_2X",
        "collapsed": true
      },
      "source": [
        "np.array([\"few\"] * 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQFuKbNzy_2b"
      },
      "source": [
        "#### Linear sequences in python\n",
        "\n",
        "In Excel if you hold shift and drag down the value of the cell will get copied downwards while the value linearly increases by 1.\n",
        "\n",
        "To get the same effect in python we use `np.arange`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OSNoMGoy_2d",
        "collapsed": true
      },
      "source": [
        "np.arange(7, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0RJXjk9y_2g"
      },
      "source": [
        "## Column operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HLjj9AJy_2g"
      },
      "source": [
        "### Dropping columns\n",
        "\n",
        "You can permanently get rid of some columns you no longer need in your dataframe with a call to `pd.DataFrame.drop`:\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html\n",
        "\n",
        "By default this method drops rows but if you pass `axis=1` it will drop columns.\n",
        "\n",
        "The main parameter (besides axis) is the `labels` which is a list of columns names you wish to drop.\n",
        "\n",
        "By default this method returns a new dataframe with the dropped column unless you also pass `inplace=True` in which case it modifies the dataframe in place and returns None. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5qr00AQy_2h",
        "collapsed": true
      },
      "source": [
        "# Droping the petal columns\n",
        "\n",
        "iris_without_petals = iris.drop(labels=[\"petal_width\", \"petal_length\"], \n",
        "                                axis=1, \n",
        "                                inplace=False)\n",
        "\n",
        "iris_without_petals.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQimVyrVy_2k"
      },
      "source": [
        "### Reordering columns\n",
        "\n",
        "Due to the implementation nature of pandas reordering columns is actually not a straight forward thing to do.\n",
        "\n",
        "To do that you need to construct a new dataframe using a dictionary and ordering the columns as you wish in it.\n",
        "\n",
        "Here in this example we will put variety first and swap the places of sepals and petals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8rTf_lsy_2l",
        "collapsed": true
      },
      "source": [
        "iris_reorder = pd.DataFrame({\n",
        "    \"variety\": iris[\"variety\"],\n",
        "    \"petal_length\": iris[\"petal_length\"],\n",
        "    \"petal_width\": iris[\"petal_width\"],\n",
        "    \"sepal_length\": iris[\"sepal_length\"],\n",
        "    \"sepal_width\": iris[\"sepal_width\"]\n",
        "})\n",
        "\n",
        "iris_reorder.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdXHEGQly_2p"
      },
      "source": [
        "#### Another way to reorder columns\n",
        "\n",
        "This is the shorter way which is easier to write as a one-liner but it can get clumsy when there are many columns.\n",
        "\n",
        "The idea is to use the usual column selection via `iris[[...]]` but instead of only a subset we list all columns, in the order we want in the new dataframe, and then we copy to get a new dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoKsn2Cly_2q",
        "collapsed": true
      },
      "source": [
        "iris[[\"variety\", \"petal_length\", \"petal_width\", \"sepal_length\", \"sepal_width\"]].copy().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYq8fcEKy_2t"
      },
      "source": [
        "### Renaming columns\n",
        "\n",
        "Sometimes you get columns with ugly and weird names and to save yourself of some typing you might want to rename them and this is where (surprise, surprise) comes the `pd.DataFrame.rename` method:\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rename.html\n",
        "\n",
        "The primary argument is called mapper and is a dictionary of old names to new names.\n",
        "\n",
        "By default it also targets rows (the index column to be precise) but if we use `axis=1` it works on column names. \n",
        "\n",
        "It also follows the `inplace` contract many other methods do in the same way.\n",
        "\n",
        "For example our column names are long to write so we can replace them with aliases.\n",
        "\n",
        "One common use case for rename is changing column names before joins."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzS9wyqAy_2v",
        "collapsed": true
      },
      "source": [
        "iris.rename({\n",
        "    # old name     new name \n",
        "    \"sepal_width\": \"sw\",\n",
        "    \"sepal_length\": \"sl\",\n",
        "    \"petal_width\": \"pw\",\n",
        "    \"petal_length\": \"pl\"\n",
        "}, axis=1).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phoohNEEy_2y"
      },
      "source": [
        "### Filtering columns\n",
        "\n",
        "Pandas dataframes have one really nifty and powerful method called `pd.DataFrame.filter` \n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.filter.html\n",
        "\n",
        "Depending on the axis paramater it can be applied to both rows and columns and by default is applied to rows but by now you know the drill `axis=1` is columns.\n",
        "\n",
        "It has 3 paramaters called `items`, `like` and `regex` of which *only one* must be passed\n",
        "- items is a list of labels you want returned \n",
        "- like is a string which must be contained in column names to be returned\n",
        "- regex is a supercharged `like` with regular expressions\n",
        "\n",
        "For example to take only the petals we can use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUEhw9ZUy_2y",
        "collapsed": true
      },
      "source": [
        "iris.filter(like=\"petal\", axis=1).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TODmuAF2y_22"
      },
      "source": [
        "## Conditional formating\n",
        "\n",
        "* https://pandas.pydata.org/pandas-docs/stable/style.html\n",
        "\n",
        "Each dataframe has a property called `style` and inside that `style` there are two methods:\n",
        "- `applymap` which allows conditional formating by element\n",
        "- `apply` which allows conditional formating by rows or columns\n",
        "\n",
        "To have styling we must use CSS. That means that our styling functions must return strings of special form.\n",
        "Through examples we will develop what that means."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yPr-y69y_23"
      },
      "source": [
        "### Color elements by type\n",
        "\n",
        "Here we check the type of each element of the dataframe and change its background color based on it.\n",
        "\n",
        "The syntax `background-color: blue` is called cascading style sheets or [CSS](https://www.w3schools.com/Css/). It always goes `property_name : property_value`. Other examples are `font-size: 16px`, `color: orange`, `font-weight: bold` etc.\n",
        "\n",
        "Notice that because we operate on elements we always return a single string describing the style."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZbIbut5y_24",
        "collapsed": true
      },
      "source": [
        "def color_elements(val):\n",
        "    \"\"\"\n",
        "    If val is string we color it blue.\n",
        "    If it is a number we color it green.\n",
        "    \"\"\"\n",
        "    \n",
        "    if type(val) == str:\n",
        "        return 'background-color: blue'\n",
        "    else:\n",
        "        return 'background-color: green'\n",
        "    \n",
        "iris.style.applymap(color_elements)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlWq6ALay_27"
      },
      "source": [
        "### Highlight the minimum value in each column\n",
        "\n",
        "Now we will use the `iris.style.apply` method which expects a function that returns a list of styles, one for element in the series.\n",
        "\n",
        "The meaning of axis here is:\n",
        "- `axis=0` work on columns\n",
        "- `axis=1` work on rows\n",
        "- `axis=None` work on the whole dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c130Dbvy_29",
        "collapsed": true
      },
      "source": [
        "def higlight_min(series):\n",
        "    n_elements = series.shape[0]\n",
        "    \n",
        "    # create an array with empty styles which are default for all items\n",
        "    styles = ['' for i in range(0, n_elements)]\n",
        "    \n",
        "    # now set the style for max position to be a orange highlight\n",
        "    styles[series.idxmin()] = 'background-color: orange'\n",
        "    \n",
        "    # finally return the list of styles\n",
        "    return styles\n",
        "\n",
        "# We can't use highlight min on the variety column so we drop it \n",
        "iris.drop(['variety'], axis=1).style.apply(higlight_min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nPujp5Iy_3B"
      },
      "source": [
        "### Make the maximum of a row italic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPmB-zXDy_3C",
        "collapsed": true
      },
      "source": [
        "def bold_max(series):    \n",
        "    n_elements = series.shape[0]\n",
        "    \n",
        "    # create an array with empty styles which are default for all items\n",
        "    styles = ['' for i in range(0, n_elements)]\n",
        "    \n",
        "    # now set the style for max position to be a orange highlight\n",
        "    styles[series.values.argmax()] = 'font-style: italic'\n",
        "    \n",
        "    # finally return the list of styles\n",
        "    return styles\n",
        "\n",
        "iris.drop(['variety'], axis=1).style.apply(bold_max, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZURxMAscy_3I"
      },
      "source": [
        "This visualizations made it easier for us to see that sepal length is almost always the largest number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPWsToNHy_3K"
      },
      "source": [
        "### Change the number format\n",
        "\n",
        "The style property also allows changing the format using the property of the same name.\n",
        "\n",
        "It takes a dictionary mapping between column names and formats.\n",
        "\n",
        "The formating language can be explored farther in:\n",
        "- https://docs.python.org/3.7/library/string.html#format-string-syntax\n",
        "\n",
        "For example we will add trailing zeros to our numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQz6UIhsy_3L",
        "collapsed": true
      },
      "source": [
        "iris.style.format({ \"sepal_length\": \"{:.3f}\", \n",
        "                    \"sepal_width\": \"{:.5f}\",\n",
        "                    \"petal_width\": \"{:.5f}\",\n",
        "                    \"petal_length\": \"{:.3f}\"\n",
        "                  })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62yHv5pPy_3T"
      },
      "source": [
        "### Barcharts in cells\n",
        "\n",
        "One cool example of styling in pandas is drawing barcharts in cells.\n",
        "- https://pandas.pydata.org/pandas-docs/stable/style.html#Bar-charts\n",
        "\n",
        "In our example we also see the first use of the `subset` parameter which is very handy to apply styling selectively and which can also be used in `apply` (rember we used drop but you can get the same effect using subset and writing out all columns except variety in the subset list). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGDXsfzoy_3U",
        "collapsed": true
      },
      "source": [
        "iris.style.bar(subset=[\"sepal_length\", \"petal_length\"], color=\"cyan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRCWwocDy_3e"
      },
      "source": [
        "## Filtering data\n",
        "\n",
        "You have already learned the basics of filtering using comparisons and masks so this section will be about bit more advanced topics. \n",
        "\n",
        "The functions covered are:\n",
        "- `isin` which tests each item of a series for membership in some list\n",
        "- `query` which filters the dataframes based on expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7lAy7N8y_3g"
      },
      "source": [
        "### IsIn example\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isin.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyshh2Rzy_3h"
      },
      "source": [
        "iris[iris.variety.isin([\"Setosa\", \"Virginica\"])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMsuY5Vay_3l"
      },
      "source": [
        "### Query\n",
        "\n",
        "This is a really powerful mechanism for filtering your data but be careful because the error messages tend to be hard to understand.\n",
        "\n",
        "- http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.query.html\n",
        "\n",
        "The syntax is best explained through a few examples but it's worth noting that you can access variables using the @ notation.\n",
        "\n",
        "Sadly it does not support column names which have dots in them so to use `query` we must rename our columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk4gjZIgy_3n"
      },
      "source": [
        "#### Example 1 \n",
        "\n",
        "Find all flowers whose sepal width is below the mean sepal width."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlTh6NgKy_3n"
      },
      "source": [
        "mean_sw = iris[\"sepal_width\"].mean()\n",
        "\n",
        "iris.query(\"sepal_width < @mean_sw\").head(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TufIxfS5y_3q"
      },
      "source": [
        "#### Example 2 \n",
        "\n",
        "Find all flowers of variety setosa whose sepal length is above 5.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh1KPDJTy_3r",
        "collapsed": true
      },
      "source": [
        "iris.query(\"sepal_length >= 5.5 and variety == 'Setosa'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYMCr5RFy_3u"
      },
      "source": [
        "#### Example 3\n",
        "\n",
        "Find all flowers whose petal_length * petal_width is smaler than 0.3 or whose variety is versicolor and sepal_width <  4.\n",
        "\n",
        "It is a made up example for you to see that you can do almost everything you do using regular filtering masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCd_vE4Ky_3v",
        "collapsed": true
      },
      "source": [
        "# Our query expression must be a single line but we can use the triple quote syntax.\n",
        "iris.query(\"\"\"\n",
        "    (petal_length * petal_width <= 0.3) or (variety == 'Versicolor' and sepal_width < 4.0)\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLe35nSMy_3y"
      },
      "source": [
        "## IF and IF ELSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKpVA_jXy_3z"
      },
      "source": [
        "In the pandas and numpy world we use the function `np.where` to achieve the effect of IF in Excel.\n",
        "\n",
        "- https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html\n",
        "\n",
        "It has two forms:\n",
        "- Form 1 where it takes only a single parameter which is a ndarray of boolean values (the condition array) and returns the indices where the array holds True\n",
        "- Form 2 where it takes the condition array, results_true array and results_false array and returns a new array which is the mix of results_true and results_false based on conditions which is what we will use here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r1jj07jy_30"
      },
      "source": [
        "#### Example 1\n",
        "\n",
        "Simple example of np.where with dummy data.\n",
        "\n",
        "Where the condition was true the resulting array has an element from x while where it was false the result is from y.\n",
        "\n",
        "The following table shows how np.where works.\n",
        "\n",
        "|condition value|x|y|result|\n",
        "|---------------|-|-|------|\n",
        "|True|*100*|10|100|\n",
        "|True|*200*|20|200|\n",
        "|False|300|*30*|30|\n",
        "|False|400|*40*|40|\n",
        "|True|*500*|50|500|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh_0VGa3y_31",
        "collapsed": true
      },
      "source": [
        "condition_array = [True, True, False, False, True]\n",
        "\n",
        "array_x = [100, 200, 300, 400, 500]\n",
        "\n",
        "array_y = [10, 20, 30, 40, 50]\n",
        "\n",
        "np.where(condition_array, array_x, array_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaU_5zRcy_34"
      },
      "source": [
        "#### Example 2\n",
        "\n",
        "The behaviour of np.where when given only a single input paramater, the condition array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH6LS8yoy_35"
      },
      "source": [
        "np.where([True, False, False, True, True, False, True])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHHhLVkiy_4D"
      },
      "source": [
        "#### Example 3\n",
        "\n",
        "Binarize the variety as Setosa or NotSetosa.\n",
        "\n",
        "This example also shows that we can use scalar values for array `x` or array `y` and these values will get replicated the necessary amount of times.\n",
        "\n",
        "This is common use case in machine learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiOXaZLXy_4E",
        "collapsed": true
      },
      "source": [
        "np.where(iris.variety == 'Setosa', 'Setosa', 'NotSetosa')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws3kSFo8y_4J"
      },
      "source": [
        "## VLOOKUP and HLOOKUP\n",
        "\n",
        "Are not implemented directly in pandas but they are very similar to relational inner joins and can also be implemented using `pd.Series.map` function.\n",
        "\n",
        "For a detailed tutorial on relational joins see the following link:\n",
        "- https://colab.research.google.com/drive/1Jedvkfma4swWG1YsWrEiFpzBmwTUcOx8\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5R2NgN0y_4K"
      },
      "source": [
        "### VLOOKUP using map\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html\n",
        "\n",
        "`map` can take a mapping function or a dictionary, for our use case the dictionary approach will suffice while the function is left for advanced use cases.\n",
        "\n",
        "We will use the `iris` dataset for the first example and we'll load `nominee_information` and `nominee_filmography` for out second example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld59hD5Cy_4N"
      },
      "source": [
        "#### Example 1 - Iris\n",
        "\n",
        "We find the average petal length per variety.\n",
        "\n",
        "Our dictionary `{'Setosa': 1.4620000000000002, 'Versicolor': 4.26, 'Virginica': 5.552}`\n",
        "corresponds to a table in excel of the format:\n",
        "\n",
        "| Variety | Average Petal Length |\n",
        "| --------| -------------- |\n",
        "| Setosa |  1.462 |\n",
        "| Versicolor | 4.26 |\n",
        "| Virginica | 5.52 |\n",
        "\n",
        "We want to attach the information about average petal length per variety to each row in the iris dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmc3lc74y_4P"
      },
      "source": [
        "average_petal_length = iris.groupby(\"variety\")[\"petal_length\"].mean()\n",
        "\n",
        "average_petal_length.to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UubONelky_4X"
      },
      "source": [
        "iris[\"average_petal_length\"] = iris[\"variety\"].map(average_petal_length.to_dict())\n",
        "\n",
        "iris.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnNt1DCxy_4b"
      },
      "source": [
        "#### Example 2 - Nominees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGm_jfUy_4c",
        "collapsed": true
      },
      "source": [
        "# 'Gerard Depardieu' : '1948-12-127' ...\n",
        "name2birthday_dict = nominee_information[[\"name\", \"birthday\"]]\\\n",
        "                        .set_index(\"name\")\\\n",
        "                        .to_dict()[\"birthday\"] # we get as result {'birthday': actual_data_we_need} so we extract\n",
        "\n",
        "nominee_filmography[\"actor_bday\"] = nominee_filmography[\"name\"].map(name2birthday_dict)\n",
        "\n",
        "nominee_filmography.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db3T7jDHy_4g"
      },
      "source": [
        "### VLOOKUP using inner join\n",
        "\n",
        "We will utilize `pd.merge` to get the same effect as we did above with map for nominee data.\n",
        "\n",
        "Notice that `actor_bday` which we had from before is same as `birthday`.\n",
        "\n",
        "The trick is to extract the two columns we need for VLOOKUP in this case `name` and `birthday`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjDQWnDly_4h",
        "collapsed": true
      },
      "source": [
        "pd.merge(left = nominee_filmography, \n",
        "         right = nominee_information[[\"name\", \"birthday\"]], # extract columns\n",
        "         how = \"inner\",\n",
        "         left_on  = \"name\", # left on vlookup criteria\n",
        "         right_on = \"name\") # right on vlookup criteria"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5Fr1FbEy_4j"
      },
      "source": [
        "### HLOOKUP as transposed data VLOOKUP\n",
        "\n",
        "The easiest way is to transpose your table with which you HLOOKUP and then use VLOOKUP using one of the two ways above whichever suits you most."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwzhFV02y_4k"
      },
      "source": [
        "#### Example 1\n",
        "\n",
        "Transform the variety column to be numbers instead of names.\n",
        "\n",
        "`iris_variety_codes` is a table in HLOOKUP format.\n",
        "\n",
        "We make a dataframe from the transposition of that table and use inner joins."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHBXWefSy_4l",
        "collapsed": true
      },
      "source": [
        "iris_variety_codes = np.array([[\"Setosa\", \"Versicolor\", \"Virginica\"], \n",
        "                               [1, 2, 3]])\n",
        "\n",
        "iris_variety_codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP0Vrp90y_4t",
        "collapsed": true
      },
      "source": [
        "tmp_df = pd.DataFrame(iris_variety_codes.T, # We transpose to get in VLOOKUP format\n",
        "                      columns=[\"variety\", \"variety_code\"]) \n",
        "\n",
        "pd.merge(iris, tmp_df, on=\"variety\").drop(\"variety\", axis=1).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOOLLNi-y_40"
      },
      "source": [
        "## RANDBETWEEN equivalent\n",
        "\n",
        "To generate random numbers in numpy we use the `numpy.random` module.\n",
        "\n",
        "It has a variety of functions from random numbers of various distributions.\n",
        "\n",
        "The equivalent of RANDBETWEEN is `randint`.\n",
        "- https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html#numpy.random.randint\n",
        "\n",
        "The upper bound is non-inclusive (so randint(5, 10) can only be one of {5, 6, 7, 8, 9})"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLgjB4Jdy_41"
      },
      "source": [
        "np.random.randint(5, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-CH-URry_44"
      },
      "source": [
        "## Pivot tables in pandas\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/reshaping.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvsuO6ZAy_45"
      },
      "source": [
        "There is lot to learn about this but we only focus on the `pd.DataFrame.pivot` and `pd.DataFrame.pivot_table` methods which are simplest to use and generally do everything you might want. For more information and more advanced techniques consult the link above.\n",
        "\n",
        "The pandas documentation has a nice image to showcase the first method.\n",
        "\n",
        "![pd_pivot](https://pandas.pydata.org/pandas-docs/stable/_images/reshaping_pivot.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-kFzuSKy_46"
      },
      "source": [
        "There are 3 parameters:\n",
        "- `index` which is the column name in the input dataframe from which to pull the rows for the pivot table. (in image foo has entries `one` and `two` which are the rows of the pivot table)\n",
        "- `columns` which is a column name in the input dataframe from which to pull the polumns (in image bar has values A, B, C which are the columns of the pivot table)\n",
        "- `values` is the name of the column in input dataframe from which to pull the table values. (in image that is baz which has values 1, 2, 3, 4, 5, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcQV6Blhy_48"
      },
      "source": [
        "#### Example - Billboards top 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4TNw59Ey_49"
      },
      "source": [
        "We want to have rows be artists, columns be years and the value for cell be the year rank for the corresponding year and artist. But first we must do some aggregations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOcTaXHXy_4-",
        "collapsed": true
      },
      "source": [
        "data_to_pivot = billboard_top_100.groupby([\"year\", \"artist\"])[\"year_rank\"].mean().reset_index()\n",
        "\n",
        "data_to_pivot.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hka6rhsmy_5B",
        "collapsed": true
      },
      "source": [
        "data_to_pivot.pivot(\n",
        "    index=\"artist\",\n",
        "    columns=\"year\",\n",
        "    values=\"year_rank\"\n",
        ").fillna(value='No Data').head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI6jTuWXy_5G"
      },
      "source": [
        "Because the grouping operation is so common pandas provides a convenience function `pd.DataFrame.pivot_table` which takes the same 3 parameters as `pd.DataFrame.pivot` but also takes an additional paramater `aggfunc` which is the name of aggregation we want (e.g. \"mean\"). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHUMT0tcy_5H",
        "collapsed": true
      },
      "source": [
        "# notice how we work on the original dataframe now, not on the result of groupby dataframe\n",
        "billboard_top_100.pivot_table(\n",
        "    index=\"artist\",\n",
        "    columns=\"year\",\n",
        "    values=\"year_rank\",\n",
        "    aggfunc=\"mean\"\n",
        ").fillna(value=\"No Data\").head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKhiS_0Sy_5M"
      },
      "source": [
        "#### Example 2\n",
        "\n",
        "Making our pivot table look nicer using conditional formating and sorting the artist names.\n",
        "\n",
        "Notice that we can combine multiple CSS properties if we separate them with a semicolon.\n",
        "\n",
        "- `text-align` is about horizontal alignment.\n",
        "- `opacity` is about visibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVAIGSj0y_5P",
        "collapsed": true
      },
      "source": [
        "def pivot_table_element_style(element):\n",
        "    if element == \"No Data\":\n",
        "        return 'opacity: 0.5' # low opacity makes the no data text fade into the background\n",
        "    else:\n",
        "        return 'background-color: green; text-align: center'\n",
        "\n",
        "# Pivot, Sort, Fill Na with No Data text, take last 10, apply styling\n",
        "billboard_top_100.pivot_table(\n",
        "    index=\"artist\",\n",
        "    columns=\"year\",\n",
        "    values=\"year_rank\",\n",
        "    aggfunc=\"mean\"\n",
        ").sort_index(ascending=False)\\\n",
        " .fillna(value=\"No Data\")\\\n",
        " .tail(10)\\\n",
        " .style.applymap(pivot_table_element_style)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfTbF606y_5U"
      },
      "source": [
        "## Charting data as in Excel\n",
        "\n",
        "To plot in python we use the matplotlib library.\n",
        "\n",
        "- https://matplotlib.org/api/pyplot_api.html\n",
        "\n",
        "There is a specialised tutorial on plotting and matplotlib available at the following link:\n",
        "- https://colab.research.google.com/drive/1SOOsVpbNp0f2anD6pOx1oVbgaa-Mp81T\n",
        "\n",
        "We will use the `sat_scores` dataset for the examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZgK6GN4y_5V"
      },
      "source": [
        "sat_scores.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onRIydxny_5Y"
      },
      "source": [
        "### Line charts\n",
        "\n",
        "We use the method called plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AhBml1jy_5a"
      },
      "source": [
        "#### Example 1 \n",
        "\n",
        "How does sat_math depend on hrs_studied. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg9-xicpy_5a",
        "collapsed": true
      },
      "source": [
        "# It is good idea to copy the data before you plot because there is always some preprocessing to be done\n",
        "plot_data = sat_scores.copy()\n",
        "\n",
        "# we must sort by hrs_studied first (which is our X axis)\n",
        "plot_data.sort_values(by=\"hrs_studied\", inplace=True)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# X axis = hrs_studied, Y axis = sat_math\n",
        "plt.plot(plot_data.hrs_studied, plot_data.sat_math)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYPBxGuuy_5k"
      },
      "source": [
        "#### Example 2 \n",
        "\n",
        "How do hours studied and maximum score of any of the 3 scores relate to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZkR3eNLy_5l",
        "collapsed": true
      },
      "source": [
        "# It is good idea to copy the data before you plot because there is always some preprocessing to be done\n",
        "plot_data = sat_scores.copy()\n",
        "\n",
        "plot_data[\"max_score\"] =\\\n",
        "    plot_data.apply(lambda row: np.max([row[\"sat_writing\"], row[\"sat_verbal\"], row[\"sat_math\"]]), axis=1)\n",
        "\n",
        "# we must sort by hrs_studied first (which is our X axis)\n",
        "plot_data.sort_values(by=\"hrs_studied\", inplace=True)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# X axis = hrs_studied, Y axis = max_score\n",
        "plt.plot(plot_data.hrs_studied, plot_data.max_score, color='xkcd:sky')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNJuBPn6y_5r"
      },
      "source": [
        "Studying more hours does not mean having higher scores even in your best test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDw7pEdCy_5s"
      },
      "source": [
        "### Bar and pie charts\n",
        "\n",
        "To draw bar and pie charts we use the methods with same names:\n",
        "- https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.bar\n",
        "- https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.pie\n",
        "\n",
        "Bar charts are also explained in detail in the ploting tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3oucpVPy_5t"
      },
      "source": [
        "#### Example 1 \n",
        "\n",
        "Bar chart of average writing score by teacher."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yuu8iLj7y_5u",
        "collapsed": true
      },
      "source": [
        "plot_data = sat_scores.copy()\n",
        "\n",
        "plot_data[\"sat_writing\"] = plot_data[\"sat_writing\"].astype(np.float64)\n",
        "\n",
        "plot_data = plot_data.groupby(\"teacher\")[\"sat_writing\"].mean().reset_index()\n",
        "\n",
        "print(plot_data)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "plt.bar(\n",
        "    x=plot_data[\"teacher\"],\n",
        "    height=plot_data[\"sat_writing\"],\n",
        "    color=[\"orange\", \"green\", \"red\", \"blue\", \"cyan\", \"magenta\", \"violet\", \"black\"]\n",
        ")\n",
        "\n",
        "plt.suptitle(\"Average SAT writing scores by teacher\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq0emBBey_5w"
      },
      "source": [
        "#### Example 2\n",
        "\n",
        "Sum of verbal scores by school as pie chart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGsRdOfpy_5x",
        "collapsed": true
      },
      "source": [
        "plot_data = sat_scores.copy()\n",
        "\n",
        "plot_data[\"sat_verbal\"] = plot_data[\"sat_verbal\"].astype(np.float32)\n",
        "\n",
        "plot_data = plot_data.groupby(\"school\")[\"sat_verbal\"].sum().reset_index()\n",
        "\n",
        "print(plot_data)\n",
        "\n",
        "# make sure that width=height so the pie does not look squashed\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "plt.pie(plot_data[\"sat_verbal\"], # data from which to get the fractions\n",
        "        labels=plot_data[\"school\"],  # labels for each pie slice (school names in this case)\n",
        "        autopct=\"%.3f\") # format string using old python formatting notation for displaying the percents\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qicNvDgsy_50"
      },
      "source": [
        "### Scatter plots \n",
        "\n",
        "- https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter\n",
        "\n",
        "Detailed information is present in the plotting guide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPXZQRisy_50"
      },
      "source": [
        "#### Example 1\n",
        "\n",
        "We will visually test if writing and verbal scores correlate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt5yDKgby_52",
        "collapsed": true
      },
      "source": [
        "plot_data = sat_scores.copy()\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.scatter(x = plot_data[\"sat_writing\"].astype(np.float32),\n",
        "            y = plot_data[\"sat_verbal\"].astype(np.float32))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbPPelKMy_54"
      },
      "source": [
        "And the answer is no, not at all but maybe some clusters exist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqnJDoW_y_54"
      },
      "source": [
        "#### Example 2\n",
        "\n",
        "Extending our scatter plot with coloring the dots by teacher to see if we can find clusters of similar performing students."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIecPQv1y_55",
        "collapsed": true
      },
      "source": [
        "plot_data = sat_scores.copy()\n",
        "\n",
        "color_dict = dict(zip(plot_data[\"teacher\"].unique(), \n",
        "                      [\"orange\", \"green\", \"red\", \"blue\", \"cyan\", \"magenta\", \"violet\", \"black\"]))\n",
        "\n",
        "print(color_dict)\n",
        "\n",
        "# See map is useful in contexts outside VLOOKUP\n",
        "# We use it here to give each student in sat_scores a color based on its teacher.\n",
        "color_sequence = plot_data[\"teacher\"].map(color_dict)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.scatter(x = plot_data[\"sat_writing\"].astype(np.float32),\n",
        "            y = plot_data[\"sat_verbal\"].astype(np.float32),\n",
        "            c = color_sequence\n",
        "           )\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOjkppety_59"
      },
      "source": [
        "We see that small isolated clusters exist but nothing significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPISXziFy_59"
      },
      "source": [
        "### Histogram plots\n",
        "\n",
        "- https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist\n",
        "\n",
        "Also see the ploting guide linked above where histograms are explained in detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIOFaq7Ly_59"
      },
      "source": [
        "#### Example 1 \n",
        "\n",
        "The histogram of scores for all 3 scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlojlZdJy_5-",
        "collapsed": true
      },
      "source": [
        "# https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.subplots\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(30, 10))\n",
        "\n",
        "axes[0].set_title(\"Writing scores\")\n",
        "axes[0].hist(sat_scores[\"sat_writing\"].astype(np.float32), bins=20, color='red')\n",
        "\n",
        "axes[1].set_title(\"Verbal scores\")\n",
        "axes[1].hist(sat_scores[\"sat_verbal\"].astype(np.float32), bins=20, color='green')\n",
        "\n",
        "axes[2].set_title(\"Math scores\")\n",
        "axes[2].hist(sat_scores[\"sat_math\"].astype(np.float32), bins=20, color='blue')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzJNeiDby_6C"
      },
      "source": [
        "### Box plots\n",
        "\n",
        "- https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.boxplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd6fHnPFy_6D"
      },
      "source": [
        "#### Example 1\n",
        "\n",
        "Box plot of hours studied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UM832ZDy_6D",
        "collapsed": true
      },
      "source": [
        "plot_data = sat_scores.copy()\n",
        "\n",
        "plot_data.dropna(inplace=True)\n",
        "\n",
        "plt.boxplot(plot_data[\"hrs_studied\"].astype(np.float32), notch=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C8iNCQzy_6F"
      },
      "source": [
        "We see the median time studied is around 90 hours and that there are no outliers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI6XpM2Fy_6G",
        "collapsed": true
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}